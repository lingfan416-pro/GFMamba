#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GFMamba å¯åŠ¨è„šæœ¬
ç”¨äºå¿«é€Ÿå¯åŠ¨æ¨ç†æˆ–WebæœåŠ¡
"""

import os
import sys
import argparse
import subprocess
import warnings
warnings.filterwarnings("ignore")

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…"""
    try:
        import torch
        import flask
        import librosa
        import cv2
        import transformers
        print("âœ… æ‰€æœ‰ä¾èµ–å·²å®‰è£…")
        return True
    except ImportError as e:
        print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
        print("è¯·è¿è¡Œ: pip install -r requirements.txt")
        return False

def check_model_files():
    """æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    config_path = "configs/mosi_train.yaml"
    model_path = "ckpt/mosi/best_valid_model_seed_42.pth"
    
    if not os.path.exists(config_path):
        print(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return False
    
    if not os.path.exists(model_path):
        print(f"âš ï¸  æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("   å°†ä½¿ç”¨éšæœºåˆå§‹åŒ–çš„æ¨¡å‹ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰")
    
    print("âœ… æ¨¡å‹æ–‡ä»¶æ£€æŸ¥å®Œæˆ")
    return True

def run_inference():
    """è¿è¡Œæ¨ç†è„šæœ¬"""
    print("ğŸ” å¯åŠ¨æ¨ç†æ¨¡å¼...")
    try:
        from inference import main
        main()
    except Exception as e:
        print(f"âŒ æ¨ç†å¤±è´¥: {e}")

def run_web_app():
    """è¿è¡ŒWebåº”ç”¨"""
    print("ğŸŒ å¯åŠ¨WebæœåŠ¡...")
    try:
        from app import app, init_inference
        if init_inference():
            app.run(host='0.0.0.0', port=5000, debug=False)
        else:
            print("âŒ æ¨ç†å™¨åˆå§‹åŒ–å¤±è´¥")
    except Exception as e:
        print(f"âŒ WebæœåŠ¡å¯åŠ¨å¤±è´¥: {e}")

def run_data_preprocessing():
    """è¿è¡Œæ•°æ®é¢„å¤„ç†"""
    print("ğŸ”§ å¯åŠ¨æ•°æ®é¢„å¤„ç†...")
    try:
        from data_preprocessing import main
        main()
    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='GFMamba å¯åŠ¨è„šæœ¬')
    parser.add_argument('--mode', choices=['inference', 'web', 'preprocess', 'check'], 
                       default='web', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--check-deps', action='store_true', help='æ£€æŸ¥ä¾èµ–')
    parser.add_argument('--check-model', action='store_true', help='æ£€æŸ¥æ¨¡å‹æ–‡ä»¶')
    
    args = parser.parse_args()
    
    print("ğŸ­ GFMamba å¤šæ¨¡æ€æƒ…æ„Ÿåˆ†æç³»ç»Ÿ")
    print("=" * 50)
    
    # æ£€æŸ¥ä¾èµ–
    if args.check_deps or args.mode != 'check':
        if not check_dependencies():
            sys.exit(1)
    
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
    if args.check_model or args.mode != 'check':
        if not check_model_files():
            if args.mode != 'check':
                print("âš ï¸  ç»§ç»­è¿è¡Œï¼Œä½†å¯èƒ½å½±å“æ€§èƒ½")
    
    # æ ¹æ®æ¨¡å¼è¿è¡Œ
    if args.mode == 'inference':
        run_inference()
    elif args.mode == 'web':
        run_web_app()
    elif args.mode == 'preprocess':
        run_data_preprocessing()
    elif args.mode == 'check':
        print("âœ… ç³»ç»Ÿæ£€æŸ¥å®Œæˆ")

if __name__ == "__main__":
    main()
